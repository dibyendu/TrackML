{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXBusmrp1vaL"
   },
   "source": [
    "# Predict Noisy Nodes in Unknown Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:12:55.530080Z",
     "start_time": "2019-07-13T16:12:55.517793Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "PATH_PREFIX = '../'\n",
    "MODEL_SAVE_DIR = 'Model(Noise)/'\n",
    "MODEL_FILE = 'model.ckpt'\n",
    "DATA_DIR = 'InclusiveEvents_Iteration1_Parsed/'\n",
    "DATA_FILE_PATH = PATH_PREFIX + DATA_DIR + 'dataset_{:04d}.json'\n",
    "OUTPUT_DIR = PATH_PREFIX + 'Prediction1/'\n",
    "OUT_FILE_PATH = OUTPUT_DIR + 'result.csv'\n",
    "\n",
    "import sys\n",
    "sys.path.append(PATH_PREFIX)\n",
    "\n",
    "FILE_NUMBER_TO_START_TESTING_FROM = 81\n",
    "FILES_TO_TEST = 20\n",
    "\n",
    "NUMBER_OF_THREADS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:13:00.523875Z",
     "start_time": "2019-07-13T16:12:58.077960Z"
    },
    "cellView": "form",
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "tjd3-8PJdK2m"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from graphGenerator import to_graph_dict_without_edges\n",
    "from plotLayer import PlotSingleImage, plotLayersSinglePlot, PlotModelPrediction\n",
    "\n",
    "import threading\n",
    "import os.path\n",
    "import ujson\n",
    "import time\n",
    "\n",
    "from graph_nets import utils_np, utils_tf\n",
    "import modelNoise as model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:13:01.251580Z",
     "start_time": "2019-07-13T16:13:01.222784Z"
    },
    "cellView": "form",
    "code_folding": [
     0,
     3,
     11,
     17,
     24
    ],
    "colab": {},
    "colab_type": "code",
    "id": "TrGithqWUML7"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "\n",
    "\n",
    "def generate_dict_graphs(raw_data, offset, batch_size):\n",
    "    input_graphs = []\n",
    "    for i in range(offset, offset + batch_size):        \n",
    "        input_graph_dict, _ = to_graph_dict_without_edges(raw_data[i])\n",
    "        input_graphs.append(input_graph_dict)\n",
    "    return input_graphs\n",
    "\n",
    "\n",
    "def create_placeholders(raw_data, offset, batch_size):\n",
    "    input_graphs = generate_dict_graphs(raw_data, offset, batch_size)\n",
    "    input_ph = utils_tf.placeholders_from_data_dicts(input_graphs)\n",
    "    return input_ph\n",
    "\n",
    "\n",
    "def create_feed_dict(raw_data, offset, batch_size, input_ph):\n",
    "    inputs = generate_dict_graphs(raw_data, offset, batch_size)\n",
    "    input_graphs = utils_np.data_dicts_to_graphs_tuple(inputs)\n",
    "    feed_dict = {input_ph: input_graphs}\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def get_noise_pos(data):\n",
    "    noisy, non_noisy = set([]), set([])\n",
    "    for pList in data['hL']:\n",
    "        for x, y in pList:\n",
    "            noisy.add((x, y))\n",
    "    for pList in data['gthL']:\n",
    "        for x, y in pList:\n",
    "            if (x, y) not in noisy:\n",
    "                raise Exception(\n",
    "                    'Ground Truth Hit Layer has extra point that doesn\\'t exist in Hit Layer'\n",
    "                )\n",
    "            non_noisy.add((x, y))\n",
    "    return non_noisy, noisy.difference(non_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:13:08.352059Z",
     "start_time": "2019-07-13T16:13:02.650912Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title Restore Model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "test_raw_data = ujson.loads(open(DATA_FILE_PATH.format(FILE_NUMBER_TO_START_TESTING_FROM), 'r').read())\n",
    "\n",
    "input_ph = create_placeholders(test_raw_data, 0, 100)\n",
    "\n",
    "num_processing_steps = 20\n",
    "\n",
    "model = model.EncodeProcessDecode(edge_output_size=None, node_output_size=2)\n",
    "\n",
    "test_outputs = model(input_ph, num_processing_steps)\n",
    "\n",
    "input_ph = utils_tf.make_runnable_in_session(input_ph)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, PATH_PREFIX + MODEL_SAVE_DIR + MODEL_FILE)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-13T16:13:17.974Z"
    },
    "cellView": "both",
    "code_folding": [
     0,
     6,
     14,
     110,
     118
    ],
    "colab": {},
    "colab_type": "code",
    "id": "6oEV1OC3UQAc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title Test Unknown Input\n",
    "\n",
    "skipped_files = []\n",
    "thread_pool = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "if not os.path.isfile(OUT_FILE_PATH):\n",
    "    out_file = open(OUT_FILE_PATH, 'w')\n",
    "    out_file.write(\n",
    "        'File number, Datapoint, # Noisy hits, # Noisy hits predicted by the model, # Noisy hits failed to predict, # True hits incorrectly predicted as noisy\\n'\n",
    "    )\n",
    "    out_file.close()\n",
    "\n",
    "\n",
    "def testing_thread(fnum):\n",
    "    f = open(DATA_FILE_PATH.format(FILE_NUMBER_TO_START_TESTING_FROM + fnum), 'r')\n",
    "    test_raw_data = ujson.loads(f.read())\n",
    "    f.close()\n",
    "\n",
    "    lock.acquire()\n",
    "    print('testing file #{:04d} ...'.format(FILE_NUMBER_TO_START_TESTING_FROM + fnum), end=' ')\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        feed_dict = create_feed_dict(test_raw_data, 0, 100, input_ph)\n",
    "        test_values = sess.run({\n",
    "            'inputs': input_ph,\n",
    "            'outputs': test_outputs\n",
    "        },\n",
    "                               feed_dict=feed_dict)\n",
    "    except Exception as e:\n",
    "        print('skipped because of exception: {}'.format(e))\n",
    "        skipped_files.append(FILE_NUMBER_TO_START_TESTING_FROM + fnum)\n",
    "        lock.release()\n",
    "        return\n",
    "    else:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('finished in {:.2f}s'.format(elapsed_time))\n",
    "    lock.release()\n",
    "\n",
    "    input = test_values['inputs']\n",
    "    output = test_values['outputs'][-1]\n",
    "\n",
    "    idds = utils_np.graphs_tuple_to_data_dicts(input)\n",
    "    odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "\n",
    "    for i in range(100):\n",
    "        raw_data = test_raw_data[i]\n",
    "        dimension = 1024\n",
    "\n",
    "        id = idds[i]\n",
    "        od = odds[i]\n",
    "        noise = np.argmax(od['nodes'], axis=-1).astype(bool)\n",
    "        predicted_noise_pos = set([])\n",
    "        for j, node in enumerate(id['nodes']):\n",
    "            if noise[j]:\n",
    "                x, y = tuple((node[:2] * dimension).astype(int))\n",
    "                predicted_noise_pos.add((x, y))\n",
    "\n",
    "        # set of points predicted to be noise points by the model\n",
    "        # print(predicted_noise_pos)\n",
    "\n",
    "        _input_non_noise_pos, input_noise_pos = get_noise_pos(raw_data)\n",
    "        missed = input_noise_pos.difference(predicted_noise_pos)\n",
    "        false_prediction = predicted_noise_pos.difference(input_noise_pos)\n",
    "\n",
    "        if len(missed) or len(false_prediction):\n",
    "            lock.acquire()\n",
    "            out_file = open(OUT_FILE_PATH, 'a')\n",
    "            out_file.write(\n",
    "                '{:04d}, {:03d}, {:03d}, {:03d}, {:03d}, {:03d}\\n'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1,\n",
    "                    len(input_noise_pos), len(predicted_noise_pos),\n",
    "                    len(missed), len(false_prediction)))\n",
    "            out_file.close()\n",
    "\n",
    "            PlotSingleImage(\n",
    "                raw_data,\n",
    "                # width=512,\n",
    "                title='Labelled image {:04d}.{:03d} for reference'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1),\n",
    "                save_loc=OUTPUT_DIR + '{:04d}.{:03d}_reference'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1))\n",
    "\n",
    "            raw_data_hl = []\n",
    "            for hL in raw_data['hL']:\n",
    "                zeros = np.zeros((1024, 1024))\n",
    "                zeros[tuple(np.array(list(hL)).T.tolist())] = 1\n",
    "                raw_data_hl.append(zeros)\n",
    "            plotLayersSinglePlot(\n",
    "                np.array(raw_data_hl),\n",
    "                title='Input image {:04d}.{:03d} to the model'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1),\n",
    "                save_loc=OUTPUT_DIR + '{:04d}.{:03d}_input'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1))\n",
    "\n",
    "            PlotModelPrediction(\n",
    "                raw_data['hL'],\n",
    "                predicted_noise_pos,\n",
    "                missed,\n",
    "                false_prediction,\n",
    "                title='Prediction by the model for image {:04d}.{:03d}'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1),\n",
    "                save_loc=OUTPUT_DIR + '{:04d}.{:03d}_output'.format(\n",
    "                    FILE_NUMBER_TO_START_TESTING_FROM + fnum, i + 1))\n",
    "            lock.release()\n",
    "\n",
    "\n",
    "for fnum in range(FILES_TO_TEST):\n",
    "    if len(thread_pool) == NUMBER_OF_THREADS:\n",
    "        thread = thread_pool.pop(0)\n",
    "        thread.join()\n",
    "    new_thread = threading.Thread(target=testing_thread, args=(fnum, ))\n",
    "    thread_pool.append(new_thread)\n",
    "    new_thread.start()\n",
    "\n",
    "for thread in thread_pool:\n",
    "    thread.join()\n",
    "\n",
    "f = open(OUTPUT_DIR + 'inconsistent.txt', 'w')\n",
    "f.write('Inconsistent files skipped while testing: {}'.format(skipped_files))\n",
    "f.close()\n",
    "print('Output generated in: {}'.format(OUT_FILE_PATH))\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "shortest_path.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "154px",
    "left": "1078px",
    "right": "20px",
    "top": "111px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
