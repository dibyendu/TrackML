{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXBusmrp1vaL"
   },
   "source": [
    "# Find Noisy Nodes in Graph with Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "tjd3-8PJdK2m"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets.demos import models\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import tensorflow as tf\n",
    "\n",
    "from graphGenerator import to_nx_graph\n",
    "\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Graph\n",
    "\n",
    "  - Graph Features: `[0]`\n",
    "  - Node Features: `[x, y] + [0, 1, 1, 1, 0, 0]` i.e. coordinate + layers\n",
    "  - Edge$(u,v)$ Features: `[distance(u,v)]`\n",
    "\n",
    "\n",
    "  - Graph Labels: `[`_Fraction of noisy nodes_`]`\n",
    "  - Node Labels: `[0, 1]` for noisy and `[1, 0]` for **NOT** noisy\n",
    "  - Edge Labels: `[0, 1]` for noisy and `[1, 0]` for **NOT** noisy\n",
    "    - $(u,v)$ is a noisy edge iff $u$ is a noisy node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_1(num_nodes, pos_array, noise):\n",
    "    distances = spatial.distance.squareform(spatial.distance.pdist(pos_array))\n",
    "    i_, j_ = np.meshgrid(range(num_nodes), range(num_nodes), indexing='ij')\n",
    "    attrs = [{\n",
    "        'distance': d,\n",
    "        'noise': noise[u]\n",
    "    } for (u, d) in zip(i_.ravel(), distances.ravel())]\n",
    "    edge_attrs = tuple(zip(i_.ravel(), j_.ravel(), attrs))\n",
    "\n",
    "    return edge_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Graph (version 2)\n",
    "\n",
    "  - Graph Features: `[0]`\n",
    "  - Node Features: `[x, y] + [0, 1, 1, 1, 0, 0]` i.e. coordinate + layers\n",
    "  - Edge$(u,v)$ Features: `[distance(u,v)]`\n",
    "\n",
    "\n",
    "  - Graph Labels: `[`_Fraction of noisy nodes_`]`\n",
    "  - Node Labels: `[0, 1]` for noisy and `[1, 0]` for **NOT** noisy\n",
    "  - Edge Labels: `[0, 1]` for noisy and `[1, 0]` for **NOT** noisy\n",
    "    - $(u,v)$ is a noisy edge iff exactly one of $u$ or $v$ is a noisy node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_2(num_nodes, pos_array, noise):\n",
    "    distances = spatial.distance.squareform(spatial.distance.pdist(pos_array))\n",
    "    i_, j_ = np.meshgrid(range(num_nodes), range(num_nodes), indexing='ij')\n",
    "    attrs = [{\n",
    "        'distance': d,\n",
    "        'noise': noise[u] != noise[v]\n",
    "    } for (u, v, d) in zip(i_.ravel(), j_.ravel(), distances.ravel())]\n",
    "    edge_attrs = tuple(zip(i_.ravel(), j_.ravel(), attrs))\n",
    "\n",
    "    return edge_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph with only Self Loops\n",
    "\n",
    "  - Graph Features: `[0]`\n",
    "  - Node Features: `[x, y] + [0, 1, 1, 1, 0, 0]` i.e. coordinate + layers\n",
    "  - Edge$(u,u)$ Features: `[0]`\n",
    "  \n",
    "\n",
    "  - Graph Labels: `[`_Fraction of noisy nodes_`]`\n",
    "  - Node Labels: `[0, 1]` for noisy and `[1, 0]` for **NOT** noisy\n",
    "  - Edge Labels: `[0, 1]` for noisy and `[1, 0]` for **NOT** noisy\n",
    "    - $(u,u)$ is a noisy edge iff $u$ is a noisy node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_3(num_nodes, pos_array, noise):\n",
    "    attrs = [{\n",
    "        'distance': 0.0,\n",
    "        'noise': n\n",
    "    } for n in noise]\n",
    "    edge_attrs = tuple(zip(range(num_nodes), range(num_nodes), attrs))\n",
    "\n",
    "    return edge_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_MODEL = model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "code_folding": [
     0,
     3,
     10,
     15,
     56,
     104,
     136,
     158,
     183,
     239,
     240,
     254,
     259,
     260
    ],
    "colab": {},
    "colab_type": "code",
    "id": "TrGithqWUML7"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "\n",
    "\n",
    "def to_one_hot(indices, max_value, axis=-1):\n",
    "    one_hot = np.eye(max_value)[indices]\n",
    "    if axis not in (-1, one_hot.ndim):\n",
    "        one_hot = np.moveaxis(one_hot, -1, axis)\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def get_node_dict(graph, attr):\n",
    "    \"\"\"Return a `dict` of node:attribute pairs from a graph.\"\"\"\n",
    "    return {k: v[attr] for k, v in graph.node.items()}\n",
    "\n",
    "\n",
    "def generate_random_graph(rand,\n",
    "                          num_nodes_min_max,\n",
    "                          dimensions=2,\n",
    "                          noisy_nodes_percentage=25):\n",
    "    '''\n",
    "    Creates a directed graph.\n",
    "    \n",
    "    Args:\n",
    "        rand: A random seed for the graph generator. Default= None.\n",
    "        num_nodes_min_max: A sequence [lower, upper) number of nodes per graph.\n",
    "        dimensions: (optional) An `int` number of dimensions for the positions.\n",
    "          Default=2.\n",
    "        noisy_nodes_percentage: (optional) An `int` number of the percentage of noisy nodes in the graph.\n",
    "          Default=25.\n",
    "    Returns:\n",
    "        The directed graph.\n",
    "    '''\n",
    "    num_nodes = rand.randint(*num_nodes_min_max)\n",
    "\n",
    "    pos_array = rand.uniform(size=(num_nodes, dimensions))\n",
    "    layers = np.random.randint(2, size=(num_nodes, 6, 2)).astype(float)\n",
    "    noise = np.full(num_nodes, False, dtype=bool)\n",
    "    idx = np.arange(num_nodes)\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:int(num_nodes * noisy_nodes_percentage / 100)]\n",
    "    noise[idx] = True\n",
    "    node_attrs = tuple(\n",
    "        enumerate({\n",
    "            'pos': p,\n",
    "            'layers': l,\n",
    "            'noise': n\n",
    "        } for p, l, n in zip(pos_array, layers, noise)))\n",
    "    edge_attrs = GRAPH_MODEL(num_nodes, pos_array, noise)\n",
    "\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_nodes_from(node_attrs)\n",
    "    graph.add_edges_from(edge_attrs)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def graph_to_input_target(graph):\n",
    "    \"\"\"Returns 2 graphs with input and target feature vectors for training.\n",
    "\n",
    "  Args:\n",
    "    graph: An `nx.DiGraph` instance.\n",
    "\n",
    "  Returns:\n",
    "    The input `nx.DiGraph` instance.\n",
    "    The target `nx.DiGraph` instance.\n",
    "  \"\"\"\n",
    "\n",
    "    def create_feature(attr, fields):\n",
    "        return np.hstack(\n",
    "            [np.ndarray.flatten(np.array(attr[field], dtype=float)) for field in fields])\n",
    "\n",
    "    input_node_fields = ('pos', 'layers')\n",
    "    input_edge_fields = ('distance', )\n",
    "    target_node_fields = ('noise', )\n",
    "    target_edge_fields = ('noise', )\n",
    "\n",
    "    input_graph = graph.copy()\n",
    "    target_graph = graph.copy()\n",
    "\n",
    "    noise_nodes = 0\n",
    "    for node_index, node_feature in graph.nodes(data=True):\n",
    "        input_graph.add_node(node_index,\n",
    "                             features=create_feature(node_feature,\n",
    "                                                     input_node_fields))\n",
    "        target_node = to_one_hot(\n",
    "            create_feature(node_feature, target_node_fields).astype(int), 2)[0]\n",
    "        target_graph.add_node(node_index, features=target_node)\n",
    "        noise_nodes += int(node_feature['noise'])\n",
    "    noise_nodes /= graph.number_of_nodes()\n",
    "\n",
    "    for sender, receiver, features in graph.edges(data=True):\n",
    "        input_graph.add_edge(sender,\n",
    "                             receiver,\n",
    "                             features=create_feature(features,\n",
    "                                                     input_edge_fields))\n",
    "        target_edge = to_one_hot(\n",
    "            create_feature(features, target_edge_fields).astype(int), 2)[0]\n",
    "        target_graph.add_edge(sender, receiver, features=target_edge)\n",
    "\n",
    "    input_graph.graph['features'] = np.array([0.0])\n",
    "    target_graph.graph['features'] = np.array([noise_nodes], dtype=float)\n",
    "    return input_graph, target_graph\n",
    "\n",
    "\n",
    "def generate_networkx_graphs(rand, num_examples, num_nodes_min_max):\n",
    "    \"\"\"Generate graphs for training.\n",
    "\n",
    "  Args:\n",
    "    rand: A random seed (np.RandomState instance).\n",
    "    num_examples: Total number of graphs to generate.\n",
    "    num_nodes_min_max: A 2-tuple with the [lower, upper) number of nodes per\n",
    "      graph. The number of nodes for a graph is uniformly sampled within this\n",
    "      range.\n",
    "\n",
    "  Returns:\n",
    "    input_graphs: The list of input graphs.\n",
    "    target_graphs: The list of output graphs.\n",
    "    graphs: The list of generated graphs.\n",
    "  \"\"\"\n",
    "    input_graphs = []\n",
    "    target_graphs = []\n",
    "    graphs = []\n",
    "    for _ in range(num_examples):\n",
    "        graph = generate_random_graph(rand, num_nodes_min_max)\n",
    "        \n",
    "        # to_nx_graph(data, model=1) # model=1(default)/2/3\n",
    "        # graph = to_nx_graph(data)\n",
    "        \n",
    "        \n",
    "        input_graph, target_graph = graph_to_input_target(graph)\n",
    "        input_graphs.append(input_graph)\n",
    "        target_graphs.append(target_graph)\n",
    "        graphs.append(graph)\n",
    "    return input_graphs, target_graphs, graphs\n",
    "\n",
    "\n",
    "def create_placeholders(rand, batch_size, num_nodes_min_max):\n",
    "    \"\"\"Creates placeholders for the model training and evaluation.\n",
    "\n",
    "  Args:\n",
    "    rand: A random seed (np.RandomState instance).\n",
    "    batch_size: Total number of graphs per batch.\n",
    "    num_nodes_min_max: A 2-tuple with the [lower, upper) number of nodes per\n",
    "      graph. The number of nodes for a graph is uniformly sampled within this\n",
    "      range.\n",
    "\n",
    "  Returns:\n",
    "    input_ph: The input graph's placeholders, as a graph namedtuple.\n",
    "    target_ph: The target graph's placeholders, as a graph namedtuple.\n",
    "  \"\"\"\n",
    "    # Create some example data for inspecting the vector sizes.\n",
    "    input_graphs, target_graphs, _ = generate_networkx_graphs(\n",
    "        rand, batch_size, num_nodes_min_max)\n",
    "    input_ph = utils_tf.placeholders_from_networkxs(input_graphs)\n",
    "    target_ph = utils_tf.placeholders_from_networkxs(target_graphs)\n",
    "    return input_ph, target_ph\n",
    "\n",
    "\n",
    "def create_feed_dict(rand, batch_size, num_nodes_min_max, input_ph, target_ph):\n",
    "    \"\"\"Creates placeholders for the model training and evaluation.\n",
    "\n",
    "  Args:\n",
    "    rand: A random seed (np.RandomState instance).\n",
    "    batch_size: Total number of graphs per batch.\n",
    "    num_nodes_min_max: A 2-tuple with the [lower, upper) number of nodes per\n",
    "      graph. The number of nodes for a graph is uniformly sampled within this\n",
    "      range.\n",
    "    input_ph: The input graph's placeholders, as a graph namedtuple.\n",
    "    target_ph: The target graph's placeholders, as a graph namedtuple.\n",
    "\n",
    "  Returns:\n",
    "    feed_dict: The feed `dict` of input and target placeholders and data.\n",
    "    raw_graphs: The `dict` of raw networkx graphs.\n",
    "  \"\"\"\n",
    "    inputs, targets, raw_graphs = generate_networkx_graphs(\n",
    "        rand, batch_size, num_nodes_min_max)\n",
    "    input_graphs = utils_np.networkxs_to_graphs_tuple(inputs)\n",
    "    target_graphs = utils_np.networkxs_to_graphs_tuple(targets)\n",
    "    feed_dict = {input_ph: input_graphs, target_ph: target_graphs}\n",
    "\n",
    "    return feed_dict, raw_graphs\n",
    "\n",
    "\n",
    "def compute_accuracy(target,\n",
    "                     output,\n",
    "                     use_nodes=True,\n",
    "                     use_edges=False,\n",
    "                     use_only_noisy=False):\n",
    "    \"\"\"Calculate model accuracy.\n",
    "\n",
    "  Returns the number of correctly predicted noisy nodes and the number\n",
    "  of completely solved graphs (100% correct predictions).\n",
    "\n",
    "  Args:\n",
    "    target: A `graphs.GraphsTuple` that contains the target graphs.\n",
    "    output: A `graphs.GraphsTuple` that contains the output graphs.\n",
    "    use_nodes: A `bool` indicator of whether to compute node accuracy or not.\n",
    "    use_edges: A `bool` indicator of whether to compute edge accuracy or not.\n",
    "    use_only_noisy: A `bool` indicator of whether to consider\n",
    "                    only noisy nodes and(or) edges for computing accuracy or not.\n",
    "\n",
    "  Returns:\n",
    "    correct: A `float` fraction of correctly labeled nodes/edges.\n",
    "    solved: A `float` fraction of graphs that are completely correctly labeled.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: Nodes or edges (or both) must be used\n",
    "  \"\"\"\n",
    "    if not use_nodes and not use_edges:\n",
    "        raise ValueError(\"Nodes or edges (or both) must be used\")\n",
    "    tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "    odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "    cs = []\n",
    "    ss = []\n",
    "    for td, od in zip(tdds, odds):\n",
    "        xn = np.argmax(td[\"nodes\"], axis=-1)\n",
    "        yn = np.argmax(od[\"nodes\"], axis=-1)\n",
    "        xe = np.argmax(td[\"edges\"], axis=-1)\n",
    "        ye = np.argmax(od[\"edges\"], axis=-1)\n",
    "        c = []\n",
    "        if use_nodes:\n",
    "            if use_only_noisy:\n",
    "                c.append((xn == yn)[xn > 0])\n",
    "            else:\n",
    "                c.append(xn == yn)\n",
    "        if use_edges:\n",
    "            if use_only_noisy:\n",
    "                c.append((xe == ye)[xe > 0])\n",
    "            else:\n",
    "                c.append(xe == ye)\n",
    "        c = np.concatenate(c, axis=0)\n",
    "        s = np.all(c)\n",
    "        cs.append(c)\n",
    "        ss.append(s)\n",
    "    correct = np.mean(np.concatenate(cs, axis=0))\n",
    "    solved = np.mean(np.stack(ss))\n",
    "    return correct, solved\n",
    "\n",
    "\n",
    "def create_loss_ops(target_op, output_ops, consider_edge_loss=True):\n",
    "    if consider_edge_loss:\n",
    "        loss_ops = [\n",
    "            tf.losses.softmax_cross_entropy(target_op.nodes, output_op.nodes) +\n",
    "            tf.losses.softmax_cross_entropy(target_op.edges, output_op.edges)\n",
    "            for output_op in output_ops\n",
    "        ]\n",
    "    else:\n",
    "        loss_ops = [\n",
    "            tf.losses.softmax_cross_entropy(target_op.nodes, output_op.nodes)\n",
    "            for output_op in output_ops\n",
    "        ]\n",
    "    return loss_ops\n",
    "\n",
    "\n",
    "def make_all_runnable_in_session(*args):\n",
    "    \"\"\"Lets an iterable of TF graphs be output from a session as NP graphs.\"\"\"\n",
    "    return [utils_tf.make_runnable_in_session(a) for a in args]\n",
    "\n",
    "\n",
    "class GraphPlotter(object):\n",
    "    def __init__(self, ax, graph, pos):\n",
    "        self._ax = ax\n",
    "        self._graph = graph\n",
    "        self._pos = pos\n",
    "        self._base_draw_kwargs = dict(G=self._graph,\n",
    "                                      pos=self._pos,\n",
    "                                      ax=self._ax)\n",
    "        self._noisy_nodes_count = None\n",
    "        self._nodes = None\n",
    "        self._edges = None\n",
    "        self._noisy_nodes = None\n",
    "        self._ax.set_axis_off()\n",
    "\n",
    "    @property\n",
    "    def noisy_nodes_count(self):\n",
    "        if self._noisy_nodes_count is None:\n",
    "            self._noisy_nodes_count = len(self.noisy_nodes)\n",
    "        return self._noisy_nodes_count\n",
    "\n",
    "    @property\n",
    "    def nodes(self):\n",
    "        if self._nodes is None:\n",
    "            self._nodes = self._graph.nodes()\n",
    "        return self._nodes\n",
    "\n",
    "    @property\n",
    "    def edges(self):\n",
    "        if self._edges is None:\n",
    "            self._edges = self._graph.edges()\n",
    "        return self._edges\n",
    "\n",
    "    @property\n",
    "    def noisy_nodes(self):\n",
    "        if self._noisy_nodes is None:\n",
    "            self._noisy_nodes = [\n",
    "                n for n in self.nodes\n",
    "                if self._graph.node[n].get('noise', True)\n",
    "            ]\n",
    "        return self._noisy_nodes\n",
    "\n",
    "    def _make_draw_kwargs(self, **kwargs):\n",
    "        kwargs.update(self._base_draw_kwargs)\n",
    "        return kwargs\n",
    "\n",
    "    def _draw(self, draw_function, zorder=None, **kwargs):\n",
    "        draw_kwargs = self._make_draw_kwargs(**kwargs)\n",
    "        collection = draw_function(**draw_kwargs)\n",
    "        if collection is not None and zorder is not None:\n",
    "            try:\n",
    "                # This is for compatibility with older matplotlib.\n",
    "                collection.set_zorder(zorder)\n",
    "            except AttributeError:\n",
    "                # This is for compatibility with newer matplotlib.\n",
    "                collection[0].set_zorder(zorder)\n",
    "        return collection\n",
    "\n",
    "    def draw_nodes(self, **kwargs):\n",
    "        \"\"\"Useful kwargs: nodelist, node_size, node_color, linewidths.\"\"\"\n",
    "        if (\"node_color\" in kwargs\n",
    "                and isinstance(kwargs[\"node_color\"], collections.Sequence)\n",
    "                and len(kwargs[\"node_color\"]) in {3, 4}\n",
    "                and not isinstance(kwargs[\"node_color\"][0],\n",
    "                                   (collections.Sequence, np.ndarray))):\n",
    "            num_nodes = len(kwargs.get(\"nodelist\", self.nodes))\n",
    "            kwargs[\"node_color\"] = np.tile(\n",
    "                np.array(kwargs[\"node_color\"])[None], [num_nodes, 1])\n",
    "        return self._draw(nx.draw_networkx_nodes, **kwargs)\n",
    "\n",
    "    def draw_edges(self, **kwargs):\n",
    "        \"\"\"Useful kwargs: edgelist, width.\"\"\"\n",
    "        return self._draw(nx.draw_networkx_edges, **kwargs)\n",
    "\n",
    "    def draw_graph(self,\n",
    "                   node_size=200,\n",
    "                   node_color=(1.0, 1.0, 1.0),\n",
    "                   node_linewidth=1.0,\n",
    "                   edge_width=1.0):\n",
    "        # Plot nodes.\n",
    "        self.draw_nodes(nodelist=self.nodes,\n",
    "                        node_size=node_size,\n",
    "                        node_color=node_color,\n",
    "                        linewidths=node_linewidth,\n",
    "                        zorder=20)\n",
    "        # Plot edges.\n",
    "        self.draw_edges(edgelist=self.edges, width=edge_width, zorder=10)\n",
    "\n",
    "    def draw_graph_with_noise(self,\n",
    "                              node_size=200,\n",
    "                              node_color=(1.0, 1.0, 1.0),\n",
    "                              noisy_node_color=(1.0, 0.0, 0.0),\n",
    "                              node_linewidth=1.0,\n",
    "                              edge_width=1.0,\n",
    "                              draw_noisy_nodes=True):\n",
    "        node_border_color = (0.0, 0.0, 0.0, 1.0)\n",
    "        if isinstance(node_color, dict):\n",
    "            c = [node_color[n] for n in self.nodes]\n",
    "        else:\n",
    "            c = node_color\n",
    "        # Plot nodes.\n",
    "        self.draw_nodes(nodelist=self.nodes,\n",
    "                        node_size=node_size,\n",
    "                        node_color=c,\n",
    "                        linewidths=node_linewidth,\n",
    "                        edgecolors=node_border_color,\n",
    "                        zorder=20)\n",
    "        # Plot noisy nodes.\n",
    "        if draw_noisy_nodes:\n",
    "            self.draw_nodes(nodelist=self.noisy_nodes,\n",
    "                            node_size=node_size,\n",
    "                            node_color=noisy_node_color,\n",
    "                            linewidths=node_linewidth,\n",
    "                            edgecolors=node_border_color,\n",
    "                            zorder=30)\n",
    "        # Plot edges.\n",
    "        self.draw_edges(edgelist=self.edges, width=edge_width, zorder=10)\n",
    "        self._ax.set_title(\"Total noisy nodes: {}\".format(\n",
    "            self.noisy_nodes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "6oEV1OC3UQAc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title Visualize example graphs\n",
    "\n",
    "seed = 1\n",
    "rand = np.random.RandomState(seed=seed)\n",
    "\n",
    "num_examples = 4\n",
    "num_nodes_min_max = (4, 5)\n",
    "\n",
    "input_graphs, target_graphs, graphs = generate_networkx_graphs(rand, num_examples, num_nodes_min_max)\n",
    "\n",
    "# print('====================================')\n",
    "\n",
    "# print(graphs[0].graph)\n",
    "# print(graphs[0].nodes)\n",
    "# print(graphs[0].nodes.data())  # or   print(digraph.nodes(data=True))\n",
    "# print(graphs[0].edges)\n",
    "# print(graphs[0].edges.data())\n",
    "\n",
    "# print('====================================')\n",
    "\n",
    "# print(input_graphs[0].graph)\n",
    "# print(input_graphs[0].nodes)\n",
    "# print(input_graphs[0].nodes.data())  # or   print(digraph.nodes(data=True))\n",
    "# print(input_graphs[0].edges)\n",
    "# print(input_graphs[0].edges.data())\n",
    "\n",
    "# print('=====================================')\n",
    "\n",
    "# print(target_graphs[0].graph)\n",
    "# print(target_graphs[0].nodes)\n",
    "# print(target_graphs[0].nodes.data())  # or   print(digraph.nodes(data=True))\n",
    "# print(target_graphs[0].edges)\n",
    "# print(target_graphs[0].edges.data())\n",
    "\n",
    "# print('====================================')\n",
    "\n",
    "w = 4\n",
    "h = int(np.ceil(num_examples / w))\n",
    "fig = plt.figure(40, figsize=(w * 4, h * 4))\n",
    "fig.clf()\n",
    "for j, graph in enumerate(graphs):\n",
    "    ax = fig.add_subplot(h, w, j + 1)\n",
    "    pos = get_node_dict(graph, 'pos')\n",
    "    plotter = GraphPlotter(ax, graph, pos)\n",
    "    plotter.draw_graph_with_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "cY09Bll0vuVj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Set up model training and evaluation\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "seed = 2\n",
    "rand = np.random.RandomState(seed=seed)\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps = 50 #10\n",
    "\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 100 #10000\n",
    "batch_size_tr = 32\n",
    "batch_size_ge = 100\n",
    "\n",
    "# Number of nodes per graph sampled uniformly from this range.\n",
    "num_nodes_min_max_tr = (8, 17)\n",
    "num_nodes_min_max_ge = (16, 33)\n",
    "\n",
    "# Data.\n",
    "# Input and target placeholders.\n",
    "input_ph, target_ph = create_placeholders(rand, batch_size_tr, num_nodes_min_max_tr)\n",
    "\n",
    "# Connect the data to the model.\n",
    "# Instantiate the model.\n",
    "model = models.EncodeProcessDecode(edge_output_size=2, node_output_size=2)\n",
    "# A list of outputs, one per processing step.\n",
    "output_ops_tr = model(input_ph, num_processing_steps) # 50 `GraphsTuple` objects\n",
    "output_ops_ge = model(input_ph, num_processing_steps) # 50 `GraphsTuple` objects\n",
    "\n",
    "# Training loss.\n",
    "loss_ops_tr = create_loss_ops(target_ph, output_ops_tr) # consider_edge_loss=False\n",
    "# Average loss across processing steps.\n",
    "loss_op_tr = sum(loss_ops_tr) / num_processing_steps\n",
    "\n",
    "# Test/generalization loss.\n",
    "loss_ops_ge = create_loss_ops(target_ph, output_ops_ge)\n",
    "loss_op_ge = loss_ops_ge[-1]  # Loss from final processing step.\n",
    "\n",
    "# Optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "step_op = optimizer.minimize(loss_op_tr)\n",
    "\n",
    "# Lets an iterable of TF graphs be output from a session as NP graphs.\n",
    "input_ph, target_ph = make_all_runnable_in_session(input_ph, target_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "WoVdyUTjvzWb"
   },
   "outputs": [],
   "source": [
    "#@title Reset session\n",
    "\n",
    "# This cell resets the Tensorflow session, but keeps the same computational\n",
    "# graph.\n",
    "\n",
    "try:\n",
    "  sess.close()\n",
    "except NameError:\n",
    "  pass\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "last_iteration = 0\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "code_folding": [
     0
    ],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2941
    },
    "colab_type": "code",
    "id": "wWSqSYyQv0Ur",
    "outputId": "73e0c8d4-e1de-4525-cba9-19328b545956",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Run training\n",
    "\n",
    "# You can interrupt this cell's training loop at any time, and visualize the\n",
    "# intermediate results by running the next cell (below). You can then resume\n",
    "# training by simply executing this cell again.\n",
    "\n",
    "# How much time between logging and printing the current results.\n",
    "log_every_seconds = 10\n",
    "\n",
    "print(\"# (iteration number), T (elapsed seconds), \"\n",
    "      \"Ltr (training loss), Lge (test/generalization loss), \"\n",
    "      \"Ctr (training fraction nodes/edges labeled correctly), \"\n",
    "      \"Str (training fraction examples solved correctly), \"\n",
    "      \"Cge (test/generalization fraction nodes/edges labeled correctly), \"\n",
    "      \"Sge (test/generalization fraction examples solved correctly)\")\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "for iteration in range(last_iteration, num_training_iterations):\n",
    "    last_iteration = iteration\n",
    "    feed_dict, _ = create_feed_dict(rand, batch_size_tr, num_nodes_min_max_tr,\n",
    "                                    input_ph, target_ph)\n",
    "    train_values = sess.run(\n",
    "        {\n",
    "            \"step\": step_op,\n",
    "            \"target\": target_ph,\n",
    "            \"loss\": loss_op_tr,\n",
    "            \"outputs\": output_ops_tr\n",
    "        },\n",
    "        feed_dict=feed_dict)\n",
    "    the_time = time.time()\n",
    "    elapsed_since_last_log = the_time - last_log_time\n",
    "    if elapsed_since_last_log > log_every_seconds:\n",
    "        last_log_time = the_time\n",
    "        feed_dict, raw_graphs = create_feed_dict(rand, batch_size_ge,\n",
    "                                                 num_nodes_min_max_ge,\n",
    "                                                 input_ph, target_ph)\n",
    "        test_values = sess.run(\n",
    "            {\n",
    "                \"target\": target_ph,\n",
    "                \"loss\": loss_op_ge,\n",
    "                \"outputs\": output_ops_ge\n",
    "            },\n",
    "            feed_dict=feed_dict)\n",
    "        correct_tr, solved_tr = compute_accuracy(train_values[\"target\"],\n",
    "                                                 train_values[\"outputs\"][-1],\n",
    "                                                 use_edges=True, use_only_noisy=True)\n",
    "        correct_ge, solved_ge = compute_accuracy(test_values[\"target\"],\n",
    "                                                 test_values[\"outputs\"][-1],\n",
    "                                                 use_edges=False, use_only_noisy=True)\n",
    "        elapsed = time.time() - start_time\n",
    "        losses_tr.append(train_values[\"loss\"])\n",
    "        corrects_tr.append(correct_tr)\n",
    "        solveds_tr.append(solved_tr)\n",
    "        losses_ge.append(test_values[\"loss\"])\n",
    "        corrects_ge.append(correct_ge)\n",
    "        solveds_ge.append(solved_ge)\n",
    "        logged_iterations.append(iteration)\n",
    "        print(\"# {:05d}, T {:.1f}, Ltr {:.4f}, Lge {:.4f}, Ctr {:.4f}, Str\"\n",
    "              \" {:.4f}, Cge {:.4f}, Sge {:.4f}\".format(iteration, elapsed,\n",
    "                                                       train_values[\"loss\"],\n",
    "                                                       test_values[\"loss\"],\n",
    "                                                       correct_tr, solved_tr,\n",
    "                                                       correct_ge, solved_ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "code_folding": [
     0
    ],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1281
    },
    "colab_type": "code",
    "id": "u0ckrMtj72s-",
    "outputId": "10c7bbc1-a4ae-4ec9-e4df-1c4498c0dad4"
   },
   "outputs": [],
   "source": [
    "#@title Visualize results\n",
    "\n",
    "# This cell visualizes the results of training. You can visualize the\n",
    "# intermediate results by interrupting execution of the cell above, and running\n",
    "# this cell. You can then resume training by simply executing the above cell\n",
    "# again.\n",
    "\n",
    "\n",
    "def softmax_prob_last_dim(x):\n",
    "    e = np.exp(x)\n",
    "    return e[:, -1] / np.sum(e, axis=-1)\n",
    "\n",
    "\n",
    "# Plot results curves.\n",
    "fig = plt.figure(1, figsize=(18, 3))\n",
    "fig.clf()\n",
    "x = np.array(logged_iterations)\n",
    "# Loss.\n",
    "y_tr = losses_tr\n",
    "y_ge = losses_ge\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.plot(x, y_tr, \"k\", label=\"Training\")\n",
    "ax.plot(x, y_ge, \"k--\", label=\"Test/generalization\")\n",
    "ax.set_title(\"Loss across training\")\n",
    "ax.set_xlabel(\"Training iteration\")\n",
    "ax.set_ylabel(\"Loss (binary cross-entropy)\")\n",
    "ax.legend()\n",
    "# Correct.\n",
    "y_tr = corrects_tr\n",
    "y_ge = corrects_ge\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.plot(x, y_tr, \"k\", label=\"Training\")\n",
    "ax.plot(x, y_ge, \"k--\", label=\"Test/generalization\")\n",
    "ax.set_title(\"Fraction correct across training\")\n",
    "ax.set_xlabel(\"Training iteration\")\n",
    "ax.set_ylabel(\"Fraction nodes/edges correct\")\n",
    "# Solved.\n",
    "y_tr = solveds_tr\n",
    "y_ge = solveds_ge\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.plot(x, y_tr, \"k\", label=\"Training\")\n",
    "ax.plot(x, y_ge, \"k--\", label=\"Test/generalization\")\n",
    "ax.set_title(\"Fraction solved across training\")\n",
    "ax.set_xlabel(\"Training iteration\")\n",
    "ax.set_ylabel(\"Fraction examples solved\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot graphs and results after each processing step.\n",
    "# Predicted noisy nodes are colored\n",
    "# from red to yellow to green, where red means the model is confident the node is\n",
    "# noisy, green means the model is confident the node is NOT noisy,\n",
    "# and yellowish colors mean the model isn't sure.\n",
    "\n",
    "max_graphs_to_plot = 1 #6\n",
    "num_steps_to_plot = 4\n",
    "node_size = 120\n",
    "min_c = 0.3\n",
    "num_graphs = len(raw_graphs)\n",
    "targets = utils_np.graphs_tuple_to_data_dicts(test_values[\"target\"])\n",
    "step_indices = np.floor(\n",
    "    np.linspace(0, num_processing_steps - 1,\n",
    "                num_steps_to_plot)).astype(int).tolist()\n",
    "outputs = list(\n",
    "    zip(*(utils_np.graphs_tuple_to_data_dicts(test_values[\"outputs\"][i])\n",
    "          for i in step_indices)))\n",
    "h = min(num_graphs, max_graphs_to_plot)\n",
    "w = num_steps_to_plot + 1\n",
    "fig = plt.figure(101, figsize=(18, h * 3))\n",
    "fig.clf()\n",
    "ncs = []\n",
    "for j, (graph, target, output) in enumerate(zip(raw_graphs, targets, outputs)):\n",
    "    if j >= h:\n",
    "        break\n",
    "    pos = get_node_dict(graph, \"pos\")\n",
    "    ground_truth = target[\"nodes\"][:, -1]\n",
    "    # Ground truth.\n",
    "    iax = j * (1 + num_steps_to_plot) + 1\n",
    "    ax = fig.add_subplot(h, w, iax)\n",
    "    plotter = GraphPlotter(ax, graph, pos)\n",
    "    plotter.draw_graph_with_noise(node_size=node_size)\n",
    "    ax.set_axis_on()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    try:\n",
    "        ax.set_facecolor([0.9] * 3 + [1.0])\n",
    "    except AttributeError:\n",
    "        ax.set_axis_bgcolor([0.9] * 3 + [1.0])\n",
    "    ax.grid(None)\n",
    "    ax.set_title(\"Ground truth\\nNoisy nodes: {}\".format(\n",
    "        plotter.noisy_nodes_count))\n",
    "    # Prediction.\n",
    "    for k, outp in enumerate(output):\n",
    "        iax = j * (1 + num_steps_to_plot) + 2 + k\n",
    "        ax = fig.add_subplot(h, w, iax)\n",
    "        plotter = GraphPlotter(ax, graph, pos)\n",
    "        color = {}\n",
    "        prob = softmax_prob_last_dim(outp[\"nodes\"])\n",
    "        for i, n in enumerate(plotter.nodes):\n",
    "            color[n] = np.array([prob[n], 1.0 - prob[n], 0.0, 1.0\n",
    "                                 ]) * (1.0 - min_c) + min_c\n",
    "        plotter.draw_graph_with_noise(node_size=node_size, node_color=color, draw_noisy_nodes=False)\n",
    "        ax.set_title(\"Model-predicted\\nStep {:02d} / {:02d}\".format(\n",
    "            step_indices[k] + 1, step_indices[-1] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#@title Print the Nth graph\n",
    "\n",
    "N_th_graph = 0\n",
    "\n",
    "target = test_values[\"target\"]\n",
    "output = test_values[\"outputs\"][-1]\n",
    "\n",
    "tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "\n",
    "td, od = tdds[N_th_graph], odds[N_th_graph]\n",
    "\n",
    "xn = np.argmax(td[\"nodes\"], axis=-1)\n",
    "yn = np.argmax(od[\"nodes\"], axis=-1)\n",
    "xe = np.argmax(td[\"edges\"], axis=-1)\n",
    "ye = np.argmax(od[\"edges\"], axis=-1)\n",
    "\n",
    "print(od['nodes'])\n",
    "print(xn)\n",
    "print(yn)\n",
    "print(xe)\n",
    "print(ye)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "shortest_path.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "154px",
    "left": "1078px",
    "right": "20px",
    "top": "111px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
